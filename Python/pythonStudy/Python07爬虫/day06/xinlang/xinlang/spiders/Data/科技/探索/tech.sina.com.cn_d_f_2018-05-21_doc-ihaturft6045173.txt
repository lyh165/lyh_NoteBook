　　来源：利维坦　　利维坦按：从技术进步的角度来看人类文明的发展，的确令人感到十分恐怖——未来学家雷·库兹韦尔将其称为（Law of Accelerating Returns）。试想，如果一个2018年的你和一个1750年的你对话，这会是一种什么情形呢？1750年的你所处的时代还没有电……你会怎么向他/她解释你的智能手机？又怎么解释互联网和核武器？　　由此，库兹韦尔认为，整个20世纪100年的进步，按照2000年的速度只要20年就能达成，而进入21世纪，按照加速回报定，虽然我们现在普遍认为自身处在弱人工智能（ANI，想一想弱智的苹果siri）时期，但距离强人工智能（AGI）乃至超人工智能（ASI）究竟还有多远，对未来不论悲观还是乐观的人，相信答案近乎一致，那就是：很快（对于数百位科学家的问卷调查显示，他们认为强人工智能出现的中位年份是2040年）。况且，看完本文中的洛可蛇怪，你可能觉得未来更加吊诡了……　　在了解洛可蛇怪之前，我们先回想一下被《复联》创造出来的奥创。奥创的出生本意是保护人类，但基于自身的思维进化却成为全人类的威胁（他认为人类是地球最大的威胁），因此反而成为了“对全人类造成威胁的人工智能”。　　再反观洛可蛇怪，俨然一副“你帮我我帮你，你不帮我我就弄你”的道德评判准则，因此对于众人而言则成为一种“诅咒”。在这个语境下，需要做选择的是一个群体而非个体，每个人都是和平饭店里的住客，只要一个点崩了，那便可能是全线崩盘的可预测结局。而洛可蛇怪并不是一颗种子，即便在未来有出现邪恶的AI的可能，也很难是仅仅因为这一思想实验的启发——但洛可蛇怪的可怕之处在于它的“催化剂效应”，当你面临选择的时候，其实已经没有选择的余地了。　　对了，最近，一直想要殖民火星的特斯拉CEO马斯克和加拿大音乐家格里姆斯（Grimes）高调亮相公开关系引来不少媒体的报道，据说二人就是因为洛可蛇怪走到一起的[格里姆斯单曲《Flesh Without Blood》有一个Rococo Basilisk的角色，“她注定要被人工智能永远折磨，像玛丽·安托瓦内特（Marie Antoinette）一样”，格里姆斯这样解释过。]。作为科幻迷，格里姆斯2010年的《Geidi Primes》则是以弗兰克·赫伯特《沙丘》中一个虚构星球命名的概念专辑。　　文/David Auerbach　　译/苦山　　校对/斩光　　原文/www.slate.com/articles/technology/bitwise/2014/07/roko_s_basilisk_the_most_terrifying_thought_experiment_of_all_time.html　　本文基于创作共同协议（BY-NC），由苦山在利维坦发布　　　　瘦形魔（Slender Man，编者注：2009年被创造出来，他的特征是身形非自然的瘦长，有一张空白、没有表情和特征的脸孔，而且经常穿一套全黑色的西装，结上黑色的领带，住在树林深处）。微笑狗（Smile Dog）。羊交（Goatse，编者注：感兴趣的请自行搜索）。这些都是由互联网滋生的都市传说。　　但没有哪个都市传说比得上洛可蛇怪（Roko’s Basilisk）那样全能而有威胁性，它就像《午夜凶铃》（The Ring）里的录像带（译者注：所有看过该录像带的人都会受到诅咒死去）。哪怕死后也不能从中解脱，因为如果你死去，洛可蛇怪会将你复活，再次折磨你。　　你确定还要继续读下去吗？因为，　　洛可蛇怪是哲学性质的思想实验与都市传说杂糅而成的产物。蛇怪首次现身于论坛，这里聚集着许多分析能力极强的人士，他们以通过数学和理性来优化个人思维、个人生活和当下世界为志趣。论坛的创始人埃利泽·尤德科夫斯基（Eliezer Yudkowsky）是科技未来界的重要人物，他开办的机器智能研究所（Machine Intelligence Research Institute）为人工智能方面的研究提供资金，以推动人工智能发展，而研究所本身则得到过彼得·蒂尔（Peter Thiel，编者注：对，就是那个既想永生而且还特有钱的资本家）和雷·库兹韦尔（Ray Kurzweil）等高调科技迷的资助鼓励。尤德科夫斯基本人对技术伦理学和决策理论的学术讨论都做出过重要贡献。　　一天，论坛用户洛可（Roko）设计了一个思想实验：　　你可能有些迷茫，但创始人埃利泽·尤德科夫斯基看懂了。他惊恐地回复道：　　尤德科夫斯基称，洛可已经给数位论坛用户带来了噩梦，使他们濒临崩溃。　　先补充一点背景知识。论坛对人类未来极为关注，尤其是奇点（the singularity）——人们假设，在未来的某个时间点（奇点），计算机的运算能力将提升到极高的程度，可能会诞生出超越人类的人工智能，同时，　　1958年，数学天才斯塔尼斯拉夫·乌拉姆（Stanislaw Ulam）和约翰·冯·诺依曼（John von Neumann）在一次对话中创造了这个术语，冯·诺依曼说：“”　　科幻作家弗诺·文奇（Vernor Vinge）和工程师、作家库兹韦尔等未来学家将这个术语普及开来，和许多对奇点感兴趣的人一样，他们相信计算机技术的发展速度呈指数级增长，这使得奇点很快就会到来——在接下来的50年内。“如果你不替自己的孩子报名人体冷冻，那你就是个糟透了的家长。”尤德科夫斯基写道。　　如果你相信奇点会来临，未来会出现极为强大的人工智能，一个显而易见的问题是，这些人工智能会是善意的还是恶意的呢？尤德科夫斯基创建的机器智能研究所目标明确，就是要将未来朝“友好的人工智能”这个方向推动。对他和许多论坛的发帖者而言，这是一个至关重要的问题，远比环境和政治问题要紧得多。　　但这不能解释为何洛可蛇怪如此令人恐惧。要想明白这点，还得再看看论坛用户所普遍信奉的一个重要信条：无时间性决策论由决策理论中的一个经典思想实验生发而来，其名为纽康姆悖论（Newcomb’s Paradox），讲述的是有一个超级智能的外星人给了你两个盒子：　　（intelligence.org/files/TDT.pdf）　　外星人给你两个选择：要么同时拿走两个盒子，要么只拿走盒子B。　　如果超级计算机预测到你会同时拿走两个盒子，那么外星人就不会在第二个盒子里放任何东西。如果超级计算机预测到你会只拿盒子B，那么外星人就在盒子B中放100万美元。　　那么，你会怎么做？记住，这台超级计算机此前从来没有出过错。　　这个问题一直困扰着决策理论学家。，　　当然，如果你这样想，而计算机也预测到你会这样想，那么盒子B就会是空的，你只能拿到1000美金。　　如果计算机的预测能力真有那么神奇，你就应该只拿走盒子B，这样就能得到整整100万美元，对不对？　　所以去他妈的预测，两个盒子都拿上！但……　　这种自由意志和天命预测之间令人发狂的矛盾，没能为纽康姆悖论找到一个解决方案，人们根据各自所做的决定自称或。（我妻子有次宣称她是个单盒党，她说：“我相信计算机。”）　　无时间性决策论对纽康姆悖论给出的建议十分明确坚决：但无时间性决策论想得更远一些。哪怕外星人嘲笑你说：“计算机说你会把两个盒子都拿走，所以我没在盒子B里放东西！”然后打开盒子B让你看清其中空无一物，你仍然应该只拿走盒子B，两手空空地离开。[我从科学家加里·德雷舍（Gary Drescher）的《善与真》（Good and Real）一书中借用了这个例子，该书试图使用无时间性决策论的一种变体来证明康德伦理体系是真实正确的。]　　这一决策的逻辑依据很难简单概括，为了做出预测，计算机需要模拟宇宙本身，这也包括你自己。　　这一切和洛可蛇怪又有什么关系呢？这个嘛，洛可蛇怪也给了你两个盒子。也许现在的你只是洛可蛇怪运行的模拟程序的产物。也许洛可蛇怪正隐晦地向你提供一种纽康姆悖论的变体，像这样：　　　　在这种情况下，你最好确保自己穷尽一生帮助创造出洛可蛇怪！因为，　　你也许在疑惑为什么论坛用户那么把这个思想实验当回事儿，毕竟它显然十分牵强。这并不是因为洛可蛇怪真的会出现，甚至不是因为它可能会出现。问题在于，如果你是无时间性决策论的忠实拥趸，那么只是想想这种交易就真的会令它更容易发生。　　毕竟，尤德科夫斯基之所以删除了所有提到洛可蛇怪的帖子，不是因为他相信它存在或将会存在，而是因为蛇怪这个想法（和这个想法背后的理念）很危险。　　但确实有一些论坛成员相信以上这一切，这就让洛可蛇怪切实成为了禁忌的知识。我本来要把它比作洛夫克拉夫特（H。 P。 Lovecraft）的恐怖小说里的内容——有个男人发现了世界禁忌的真理，放出了克苏鲁，陷入疯癫——但我发现尤德科夫斯基已经替我做了这件事，洛可本人则将一切怪罪于论坛，因为说到底，是这个论坛促使他产生了蛇怪这个想法：“”他这样写道。　　如果你并不认同洛可蛇怪实验的理论基础，也不打算向你永恒的邪恶机器主宰屈服，那么洛可蛇怪对你就毫无威胁。（说来讽刺，它只有可能对相信尤德科夫斯基理论的人心理健康产生危害。）　　但我确实认为这件事背后有个更为严肃的问题，因为埃利泽·尤德科夫斯基和其他所谓的超人类主义者已经为他们的项目吸引了大量的声望和资金，这些声望和资金主要来自富有的科技迷们。我认为他们的项目（其主要内容似乎就是发论文、开会）不太可能创造出洛可蛇怪或是埃利泽大善神。　　比起洛可蛇怪，我更担心那些自认为已经凌驾于传统道德体系之上的人。尤德科夫斯基和他计划创造的友好人工智能一样，是一个道德功利主义者：他曾明确表示，当不得不做出选择时，比起让许多人眼里进灰（公平起见，他说的是非常多的人），更应该选择折磨某一个人50年。　　谁都不太可能面临这样的抉择，连上帝都不会，但如果换个情况呢？假如Slate网站上（译者注：即本文发布的网站）有个尖刻的科技版专栏作家写了一篇文章，内容有关一个能摧毁人们心智的思想实验，结果伤到了读者，阻止了历史向奇点发展，使友好的人工智能没法出现呢？这种情况下，我生命中任何潜在的幸福加起来都远远抵不过我眼下正造成的危害。而假如接受了人工冷冻术的埃利泽·尤德科夫斯基在奇点后醒来，决定在模拟中让我选择要不要写这篇专栏文章……拜托了，无所不能的埃利泽啊，别折磨我。