　　　　文/杨苏颖　　来源：智能相对论（ID：aixdlun）　　自古站着说话都是不会腰疼的，在这样一个鼓励质疑的社会气氛当中，戾气彷佛成了最好的鼓励。去中心化的时代，人人都有麦克风，网络发言的成本达到了历史最低。　　近日，知乎正用AI识别“答非所问”和“不友善”又被媒体反复引用。前不久，罗永浩“精日没啥”的言论相继被北京日报和广州日报点名批评，微博的评论区“锤粉”、“锤黑”的论战比罗永浩本人的演讲还“好看”，但是这种“好看”是靠着你来我往的火药桶攻击而炒起来的热度。广州日报官方微博下面，“小心锤蛆”评论排在热评的第一位，“智障”、“走狗”、“SB”的字眼也屡见不鲜。微博的骂战如此壮烈让“路人”都不忍直视，更不谈上不来理性的分析罗永浩是否是精日，精日是什么的问题。　　　　评论区比内容本身还好看，现在已经不仅仅是个口上的噱头了。各大社交和问答平台都开始注意到评论区的运营。此前，为了提高评论审核的效率，有效管理微博评论，微博也开始有所动作，面向头部用户和正式会员用户开通评论审核的功能，在开放此功能之后，用户可以对自己微博下的评论实现评论先审后放。　　因此，如果把文章本身称为“第一内容区”的话，那么评论区俨然已经成为蓬勃发展的“第二内容区”，今天注重评论区的管理开始变得越来重要。在4月的GMIC大会上，知乎合伙人、高级副总裁李大海做了一个分享，称知乎正在打造“智慧社区”，并透露出，在知乎的内容社区当中，AI已经可以开始进行语义识别和语境判断。因为单单依赖人工的力量来管理内容，实在不是一个高效的选择。 　　在知乎里面，现在有一个2岁多的机器人叫“瓦力”，目前这个机器人可以在线上快速响应答非所问和不友善的内容，减少像歧视，恶意贴标签，辱骂等等低质内容对用户的干扰。但是目前受到NPL（自然语言处理）自身的局限性和平台运营存在的相应问题，这个智慧社区还存在着不少问题。　　如果说人工智能算法能够通过监测人们说话时的声学特征，比如发音频率，声音高低，以及语气的变化，来识别人类说话的情绪类型是一项很了不起的技术。那么直接通过NPL来鉴定人类的说话情绪则是更难上加难的操作。因为一个脏字不带，一个敏感词都没有的句子，AI很难总结出它们的共同特征从而有针对性的挑选出来作为负面言论的代表，真正成为评论区的“清道夫”。　　另外，目前知乎的机器学习方式是利用知乎的中文语料库，调动用户积极对语料进行手动标注来训练AI，这在机器的监督学习中是必不可少的一步。但新的技术正在涌现，比如强化学习和in-streamsupervision，数据可以在自然使用过程中获得标注。或者，知乎还可以学习科大讯飞建立语音云平台一样，引入语料云平台，这样可以从其他更广泛的渠道以更快的速度发现更新的语料。因为等到知乎中文语料库中有足够的新兴语料可以让机器进行学习时，代表这类语料的存在在平台上已经比较广泛了，如果此种语料是恶性的，那么则说明评论的内容生态已经遭到了一定污染。　　　　把目光投到国外，国外的那些顶级媒体则更早就开始重视到评论区的重要性并开始用技术对评论区进行打理。纽约时报与Jigsaw（谷歌Alphabet旗下科研团队）合作，并牵头华盛顿邮报、Mozilla基金会成立了The Coral Project（珊瑚项目），研究如何改进在线评论，并孵化一系列开源工具为各大新闻编辑室提供技术支持。2015年时，纽约时报采用的评论体系会依靠算法对不同用户的评论进行优先级排序，并且决定哪些用户的评论可以不用经过较长时间的人工审查就可以发布。　　但是，人工智能到底是蓝海还是深坑还需要时间的检验，智能相对论（aixdlun）分析师杨苏颖还想在此提出利用人工智能管理评论内容生态的两个讨论点：　　1、AI的背后是人，如果人不想解决某个问题，那么AI也只是噱头和摆设。最近，在某草根公众号中看到一篇文章，名叫《欲加之罪，何患无词》，谈论的是有关喜马拉雅APP内容付费的问题，该公众号的主人在喜马拉雅上传了自己解读书籍《乌合之众》音频，后突然因版权投诉而被下架了。喜马拉雅方面的客服称因为已经有解读该书的付费音频存在，所以再上传解读该书的音频就算作是侵权。对于某一个单一的知识付费内容能不能垄断市场暂且不论，这个唯一被平台认可的《乌合之众》付费音频下面的评论却显示出这个付费的内容并不尽如人意。　　但是平台不顾听众在评论区的反馈，完全没有用心传播优质内容的匠心。如今许多平台都尝试使用AI进行评论区的管理，但是AI要执行的始终是人的想法，就算AI通过各种识别的功能发现了这个问题，如果人并不想解决这个问题，那么AI的设立又还有什么用处呢？　　2、在评论区，AI通过识别用户言论来给每一个用户贴标签，这一点很难说不是在将每个人的言论权利做一个高矮次序的排列。许多用AI来管理评论区的平台谈到技术方面都会说到现在可以利用AI可以对用户进行标签，有点儿像所谓的社会信用体系。但这种看似合理的信用体系背后的问题是：争了好几百年来的平等言论权就这么被AI再次剥夺了？　　站在社会学的角度，我们常常在讨论的是标签对人性的压抑以及标签给人带来的种种痛苦，并思索着如何才能让社会环境进一步“去标签化”。但我们没注意到的是，AI正在利用我们在网络留下的数据对我们进行标签化。如果，某个人曾经发布过一些负面言论，那么经过AI的识别判定后，他的言论可能今后永远只能在评论区的下游飘荡。潜在地，这个人是不是相当于被间接削弱了言论权呢？你可以发言，但是不会有人看得到。这也代表了在网络社区当中话语权会被进一步中心化。所以，AI也应该该考虑一下去标签化的问题，并建立去标签化的机制。每个人都有被原谅的机会，但是数据会知道这一点吗？　　技术非但没有使信息自由流动，反而建立了更加庞大的信息孤岛。在微信当中，只有互为好友的人才能看到在同一个人朋友圈下面的评论互动，这样的评论机制在微信当中建立起的无数个不同的小圈子，小圈子之间隔着高高低低的围墙。微信虽然帮助我们连接了更多的人，但是却把父母给隔离了起来。她/他能够看到的评论区永远只有自己一个人，想要通过你的朋友圈了解你的生活，了解你的朋友和外面的世界，但是技术却阻断了这么简单的念想，他不知道你平常是怎么和朋友打趣，甚至不知道你说的佛系，在评论区看不到更多的解释，还以为你要去出家，赶紧打个电话过来询问。但为了避免你麻烦的解释过程，技术还可以建立起更多“去麻烦”的机制，比如分组可见。对于我们而言我们是在提高自己的生活效率，更好地管理自己的生活，但是对于父母而言，他们只是被强制削去了知情权，这实际就是剥夺发言权的前一步。　　在日常的信息获取当中，剥夺话语权的方式是很隐晦。它通常会先剥夺你的知情权。今日头条的人工智能算法推荐信息，过度迷信算法的精准性，实则把用户困在它制造的信息孤岛。由互联网所打破的信息壁垒，在今日头条的作用下被重新建立起来，只是这背后更为深刻的是，同质信息的轰炸阻断了那些没有主动获取信息能力的人上行的通道。在这样庞大的信息社区当中，平台需要建立自己的人文价值观和社会责任，一旦当它们的价值开始混乱，钱就会成为唯一的尺度。人工智能是技术的又一次升级，但是人工智能不能成为一切腐朽旧思想的避难所，不能包庇价值观的混乱，也不能纵容技术平台对用户话语权的剥夺。如何在保护话语权和保护平台社区环境之间寻求一个平衡点，是运用AI管理评论区需要思考的第一个问题。　　评论区的“黄金屋”和“颜如玉”在今天是显而易见的，但平台的内容运营者们想要在这上面使力则还需要继续探索。AI帮助进行智能评论区管理是件好事，但在AI的背后还潜藏着太多未解的难题，管理者们一定要带着问号去利用好AI，让AI成为内容管理的福音。　　
										
									